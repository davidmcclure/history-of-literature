{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The HTRC extracted feature data\n",
    "\n",
    "Ok, so - the history of \"literature.\" As a starting point, I decided to do experiment with the Hathi Trust \"extracted features\" data set, which is attractive in this context for a couple of reasons. First, it's huge - just shy of 5M volumes, and, in theory, we could eventually get our hands on the other ~10M volumes at Illinois. Second, it's a broad mix of texts - it's essentially a huge digital bookshelf hauled in out of the stacks in the library - fiction, nonfiction, periodicals, reference texts, everything under the sun. I think this is good for this project, since, in a sense, just looking at the word \"literature\" _in_ literature would arguably box us into a very particular type of usage - the text-within-the-text, literature thinking about itself. Which could be interesting in and of itself, but possibly not a great place to start for a general treatment of the question.\n",
    "\n",
    "The Hathi data looks like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"aeu.ark:/13960/t0000d036\",\n",
    "  \"metadata\": {\n",
    "    \"pubDate\": \"1878\",\n",
    "    \"handleUrl\": \"http://hdl.handle.net/2027/aeu.ark:/13960/t0000d036\",\n",
    "    \"language\": \"eng\",\n",
    "    \"imprint\": \"[s.n.], 1878.\",\n",
    "    \"htBibUrl\": \"http://catalog.hathitrust.org/api/volumes/full/htid/aeu.ark:/13960/t0000d036.json\",\n",
    "    \"oclc\": \"716097827\",\n",
    "    \"schemaVersion\": \"1.2\",\n",
    "    \"dateCreated\": \"2015-02-12T20:51\",\n",
    "    \"title\": \"Amphioxus and Ascidian our gelatinous ancestors\"\n",
    "  },\n",
    "  \"features\": {\n",
    "    \"pageCount\": 6,\n",
    "    \"pages\": [\n",
    "      {\n",
    "        \"tokenCount\": 312,\n",
    "        \"languages\": [\n",
    "          {\n",
    "            \"en\": \"1.00\"\n",
    "          }\n",
    "        ],\n",
    "        \"header\": {\n",
    "          \"tokenPosCount\": {},\n",
    "          \"tokenCount\": 0,\n",
    "          \"emptyLineCount\": 0,\n",
    "          \"sentenceCount\": 0,\n",
    "          \"lineCount\": 0\n",
    "        },\n",
    "        \"seq\": \"00000001\",\n",
    "        \"body\": {\n",
    "          \"tokenPosCount\": {\n",
    "            \"presence\": {\n",
    "              \"NN\": 1\n",
    "            },\n",
    "            \"kind\": {\n",
    "              \"NN\": 1\n",
    "            },\n",
    "            \"investigations\": {\n",
    "              \"NNS\": 1\n",
    "            },\n",
    "            \"vertebraie\": {\n",
    "              \"NN\": 1\n",
    "            },\n",
    "            \"wise\": {\n",
    "              \"JJ\": 1\n",
    "            },\n",
    "            \"series\": {\n",
    "              \"NN\": 1\n",
    "            },\n",
    "            \"177*.\": {\n",
    "              \"VBG\": 1\n",
    "            },\n",
    "            \"the\": {\n",
    "              \"DT\": 10\n",
    "            },\n",
    "            \"Vertebrata\": {\n",
    "              \"NNP\": 1\n",
    "            },\n",
    "            \"Past\": {\n",
    "              \"NNP\": 1\n",
    "            },\n",
    "            \"he\": {\n",
    "              \"PRP\": 2\n",
    "            },\n",
    "            \"mean\": {\n",
    "              \"VBP\": 1\n",
    "            },\n",
    "            \"far-searching\": {\n",
    "              \"JJ\": 1\n",
    "            },\n",
    "            \"ado\": {\n",
    "              \"NN\": 1\n",
    "            },\n",
    "            \"(\": {\n",
    "              \"-LRB-\": 1\n",
    "            },\n",
    "            \"tender\": {\n",
    "              \"VB\": 1\n",
    "            },\n",
    "            \"of\": {\n",
    "              \"IN\": 9\n",
    "            },\n",
    "\n",
    "            // more words...\n",
    "            \n",
    "          },\n",
    "          \"tokenCount\": 312,\n",
    "          \"emptyLineCount\": 20,\n",
    "          \"sentenceCount\": 15,\n",
    "          \"lineCount\": 66\n",
    "        },\n",
    "        \"footer\": {\n",
    "          \"tokenPosCount\": {},\n",
    "          \"tokenCount\": 0,\n",
    "          \"emptyLineCount\": 0,\n",
    "          \"sentenceCount\": 0,\n",
    "          \"lineCount\": 0\n",
    "        },\n",
    "        \"emptyLineCount\": 20,\n",
    "        \"sentenceCount\": 15,\n",
    "        \"lineCount\": 66\n",
    "      },\n",
    "      \n",
    "      // more pages...\n",
    "      \n",
    "    ],\n",
    "    \"schemaVersion\": \"2.0\",\n",
    "    \"dateCreated\": \"2015-02-19T17:21\"\n",
    "  }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Basically - simple bibliographic metadata about the volume, and then per-page token counts, broken out by page section and part-of-speech. I actually think that the \"page\" is a nice unit of study for this projet, in a lot of ways. As discussed at the Concept Lab meeting this week - this scale is a nice middle-ground between the tight scope of the \"sentence\" or \"phrase,\" the unit of analysis for the traditional notion of colocation in corpus linguistics, and the broader notion of the \"document,\" as used in bag-of-words paradigms like topic modeling or information retrieval. It's a small constituent part of a text, but still big enough to lasso a meaningful swath of semantic information.\n",
    "\n",
    "## Data wrangling\n",
    "\n",
    "So, where to start? To say anything meaningful about changes in word frequencies over time around \"literature,\" we have to be able to compare against the baseline changes in volume over time, or else we'd almost certainly just be picking up on these overall trends. Eg - words like \"thou\" or \"magick\" show up much less frequently around literature over time in an absolute sense, but this is just because they become generally less prevalent, not because of any real change in the conceptual attraction of the words.\n",
    "\n",
    "What we need, then, is per-year token counts for each unique token in the corpus. This is simple in concept - just loop through the volumes and build up a big `year -> token -> count` map. But in practice, because of the size of the Hathi data, this gets complicated, especially if we want to write code that will scale up to the complete data set. The volumes are stored as `.bz2` JSON files, which means that they need to be inflated on-the-fly during extraction runs, which is very slow. (But, Ted Underwood advises against trying to pre-extract the volumes, which more than doubles the ~2TB footprint of the corpus.) Then there's the question of how to store the counts. It becomes unweildy to just cake up Python dictionaries with many (tens of) millions of keys in RAM, and, even if it fits - what then? Just compute against it as a raw data structure? Dump it off as a huge, many-gigabyte JSON file, load it back into memory every time? Lots of surface area for failure and headache there. Work at this scale calls out for some kind of real data store, but this leads to performance problems beacause there's always a significant indexing overhead if you shovel data into Postgres, Redis, etc.\n",
    "\n",
    "After a bit of experimentation, here's the flow I settled on:\n",
    "\n",
    "- Loop through the volume paths in groups of 5-10k. For each successive group, use Python's `multiprocessing` module to spawn off a pool of workers that process the paths in parallel - inflate the `.bz2`, make a `Volume` instance, and return a cleaned `token -> count` map for the volume. Since reading the files is heavy IO, the parallelization gives a huge speedup.\n",
    "\n",
    "\n",
    "- As these results come back to the controller process, build up an in-memory cache of the `year -> token -> count` totals.\n",
    "\n",
    "\n",
    "- Only when all the paths in the group have been processed, flush the cached counts into Postgres using the new `UPSERT` syntax in 9.5, which makes it possible to increment each of the year + token counters with a single query.\n",
    "\n",
    "\n",
    "- Empty the cache, repeat with the next group of paths.\n",
    "\n",
    "Why the \"groups\", instead of just processing and indexing each volume individually? This has the effect of bundling together the increment queries, which reduces the number of times we have to go across the wire to Postgres. Eg, say three volumes produce these token/year/count triples:\n",
    "\n",
    "```\n",
    "(\"literature\", 1900, 10)\n",
    "(\"literature\", 1900, 20)\n",
    "(\"literature\", 1900, 30)\n",
    "```\n",
    "\n",
    "Instead of running three separate queries, by building up the temporary caches in-memory these get merged into a single update that has the same effect:\n",
    "\n",
    "```\n",
    "(\"literature\", 1900, 60)\n",
    "```\n",
    "\n",
    "But, since we flush the cache after each ~10k volumes, we never build up too much memory pressure on the machine.\n",
    "\n",
    "## Counting words\n",
    "\n",
    "The word counts are generated and accessed via the `Count` class, a SQLAlchemy model. To get an ordered list of years (our X-axis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1635, 1656, 1705, 1713, 1714, 1715, 1716, 1752, 1753, 1754, 1756, 1763, 1764, 1774, 1780, 1783, 1784, 1785, 1787, 1789, 1790, 1793, 1795, 1797, 1798, 1800, 1801, 1803, 1804, 1809, 1810, 1812, 1813, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1826, 1827, 1828, 1830, 1831, 1832, 1833]\n"
     ]
    }
   ],
   "source": [
    "from htrc.models import Count\n",
    "\n",
    "years = Count.years()\n",
    "print(years[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sorted list of unique tokens (so we can iterate over all observed words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'abandoned', 'ability', 'able', 'about', 'above', 'abroad', 'absence', 'absolute', 'absolutely', 'abstract', 'abuse', 'academic', 'academy', 'accept', 'acceptable', 'accepted', 'access', 'accident', 'accompanied', 'accomplished', 'according', 'account', 'accounts', 'accurate', 'accused', 'achieve', 'achieved', 'achievement', 'acid', 'acquired', 'across', 'act', 'acting', 'action', 'actions', 'active', 'activities', 'activity', 'actor', 'actors', 'actress', 'acts', 'actual', 'actually', 'ad', 'adam', 'adams', 'add', 'added']\n"
     ]
    }
   ],
   "source": [
    "tokens = Count.tokens()\n",
    "print(tokens[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the basic count data. To get the total number of tokens observed in a given year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156144"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count.year_count(1912)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, to get the number of times that word X appeared in year Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count.token_year_count('literature', 1912)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us what we need for aggregate time-series plots. Here's total volume by year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "QueuePool limit of size 5 overflow 10 reached, connection timed out, timeout 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/pool.py\u001b[0m in \u001b[0;36m_do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_overflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msqla_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/util/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-30881142272a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/htrc/models/count.py\u001b[0m in \u001b[0;36myear_count\u001b[0;34m(cls, year)\u001b[0m\n\u001b[1;32m    164\u001b[0m         )\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36mscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2722\u001b[0m         \"\"\"\n\u001b[1;32m   2723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2724\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2725\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36mone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \"\"\"\n\u001b[0;32m-> 2693\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoflush\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_populate_existing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2736\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_and_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2738\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connection_from_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m_execute_and_instances\u001b[0;34m(self, querycontext)\u001b[0m\n\u001b[1;32m   2747\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2748\u001b[0m             \u001b[0mclause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquerycontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2749\u001b[0;31m             close_with_result=True)\n\u001b[0m\u001b[1;32m   2750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2751\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerycontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m_connection_from_session\u001b[0;34m(self, **kw)\u001b[0m\n\u001b[1;32m   2738\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connection_from_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m         conn = self.session.connection(\n\u001b[0;32m-> 2740\u001b[0;31m             **kw)\n\u001b[0m\u001b[1;32m   2741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mconnection\u001b[0;34m(self, mapper, clause, bind, close_with_result, execution_options, **kw)\u001b[0m\n\u001b[1;32m    891\u001b[0m         return self._connection_for_bind(bind,\n\u001b[1;32m    892\u001b[0m                                          \u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                                          execution_options=execution_options)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connection_for_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_connection_for_bind\u001b[0;34m(self, engine, execution_options, **kw)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransaction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             return self.transaction._connection_for_bind(\n\u001b[0;32m--> 898\u001b[0;31m                 engine, execution_options)\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextual_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36m_connection_for_bind\u001b[0;34m(self, bind, execution_options)\u001b[0m\n\u001b[1;32m    332\u001b[0m                         \"given Connection's Engine\")\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextual_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mcontextual_connect\u001b[0;34m(self, close_with_result, **kwargs)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         return self._connection_cls(\n\u001b[1;32m   2038\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2039\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_pool_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m             \u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m             **kwargs)\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_wrap_pool_connect\u001b[0;34m(self, fn, connection)\u001b[0m\n\u001b[1;32m   2072\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2074\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2075\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/pool.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \"\"\"\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_threadlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_ConnectionFairy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/pool.py\u001b[0m in \u001b[0;36m_checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_checkout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreadconns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfairy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfairy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0mfairy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mfairy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/pool.py\u001b[0m in \u001b[0;36mcheckout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheckout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mdbapi_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dclure/Projects/htrc-dev/env/lib/python3.5/site-packages/sqlalchemy/pool.py\u001b[0m in \u001b[0;36m_do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1051\u001b[0m                         \u001b[0;34m\"QueuePool limit of size %d overflow %d reached, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m                         \u001b[0;34m\"connection timed out, timeout %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m                         (self.size(), self.overflow(), self._timeout))\n\u001b[0m\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inc_overflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: QueuePool limit of size 5 overflow 10 reached, connection timed out, timeout 30"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs = range(1700, 1920)\n",
    "\n",
    "ys = []\n",
    "for year in xs:\n",
    "    ys.append(Count.year_count(year))\n",
    "    \n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
