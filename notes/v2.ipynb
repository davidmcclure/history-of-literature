{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of \"literature\" - Co-occurrence in Hathi Trust\n",
    "\n",
    "So, to pick up where we left off last time. Over the course of the last two weeks, I've completed the basic page-level co-occurrence analysis - tracking the diachronic correlation or \"attachment\" of different words with \"literature.\" This turned out to be a bit more complex than I thought, but, after coming at it from a couple different directions, I think I've found an angle that produces some interesting results.\n",
    "\n",
    "After getting the overall counts for each token in each year (the \"baseline\" counts that we looked at before), the next step was to extract a second, filtered set of counts that would record the number of times each word appeared on pages that contain \"literature.\"\n",
    "\n",
    "The two sets of counts get stored in separate tables:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE count (\n",
    "\ttoken VARCHAR NOT NULL, \n",
    "\tyear INTEGER NOT NULL, \n",
    "\tcount INTEGER NOT NULL, \n",
    "\tPRIMARY KEY (token, year)\n",
    ");\n",
    "CREATE TABLE anchored_count (\n",
    "\ttoken VARCHAR NOT NULL, \n",
    "\tyear INTEGER NOT NULL, \n",
    "\tanchor_count INTEGER NOT NULL, \n",
    "\tcount INTEGER NOT NULL, \n",
    "\tPRIMARY KEY (token, year, anchor_count)\n",
    ");\n",
    "```\n",
    "\n",
    "The `count` table stores the overall, unfiltered counts for words on all pages, broken out by year. Eg:\n",
    "\n",
    "**`\"literature\" / 1900 / 89608`**\n",
    "\n",
    "Meaning, \"literature\" appears 89,608 times in 1900. Meanwhile, `anchored_count` stores counts just for words that appear on pages that contain \"literature,\" broken out by the year and by the number of times that \"literature\" itself appears on the page in question. (This will allow us to dig into the question of whether there's a difference between pages that are really _about_ literature, as opposed to pages that just use the word in passing.) Eg:\n",
    "\n",
    "**`\"poetry\" / 1900 / 4 / 5967`**\n",
    "\n",
    "Meaning - in 1900, \"poetry\" appears 5,967 times on pages where \"literature\" appears 4 times. In total, the extraction run chewed through all ~820k volumes in the Harvard collection in Hathi Trust, and observed a total of **43.5 billion** tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43401065888\n"
     ]
    }
   ],
   "source": [
    "from hol.models import Count, AnchoredCount\n",
    "\n",
    "print(Count.total_token_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is still only about 1/5 of the whole collection. The Harvard collection, it turns out, is basically a C19 corpus. Here's the overall volume trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10805a080>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEZCAYAAAB1mUk3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npDeZKq4aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107e08c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "years = range(1750, 1920)\n",
    "\n",
    "series = Count.year_count_series(years)\n",
    "\n",
    "plt.title('Overall token volume, all pages')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(*zip(*series.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-likelihoods, ranked and scaled\n",
    "\n",
    "So, two sets of counts - one for all pages, and the other just for pages that contain \"literature.\" Even though both are drawn from the same corpus, we can think of them as representing two distinct corpora - the corpus of \"literature\" pages, and the corpus of all pages, a sub-corpus and a super-corpus. The goal is simple - which words appear in the literature corpus at a higher-than-expected rate, when compared against the overall frequencies in the super-corpus?\n",
    "\n",
    "There are a couple of ways to go about this - a log-likelihood tests, the Mann-Whitney ranks test, and others. The log-likelihood is the most canonical and straightforward, though, so let's start with that. To measure the distinctiveness of \"history\" in 1900, we need 4 pieces of information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times \"history\" appears on pages that contain \"literature\":\n",
      "39363 \n",
      "\n",
      "The number of times \"history\" appears on all pages:\n",
      "291676 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = AnchoredCount.token_year_count('history', 1900)\n",
    "print('The number of times \"history\" appears on pages that contain \"literature\":')\n",
    "print(a, '\\n')\n",
    "\n",
    "b = Count.token_year_count('history', 1900)\n",
    "print('The number of times \"history\" appears on all pages:')\n",
    "print(b, '\\n')\n",
    "\n",
    "c = AnchoredCount.year_count(1900)\n",
    "print('The total number of tokens observed on pages that contain \"literature\":')\n",
    "print(c, '\\n')\n",
    "\n",
    "d = Count.year_count(1900)\n",
    "print('The total number of tokens observed on all pages:')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use scipy's `chi2_contingency` function to calculate the log-likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "g, p, dof, exp = chi2_contingency(\n",
    "    np.array([[a, b], [c, d]]),\n",
    "    lambda_='log-likelihood',\n",
    ")\n",
    "\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is expensive to compute for an individual word, but it can be sped up by querying big batches of counts and calculating the scores in bulk. These get shoveled into a `score` table, which stores the token, the year, and the log-likelihood (\"score\"):\n",
    "\n",
    "```sql\n",
    "CREATE TABLE score (\n",
    "\ttoken VARCHAR NOT NULL, \n",
    "\tyear INTEGER NOT NULL, \n",
    "\tscore FLOAT NOT NULL, \n",
    "\tPRIMARY KEY (token, year)\n",
    ");\n",
    "```\n",
    "\n",
    "Once we've filled in this table with log-likelihood scores for each token in each year, we can generate a list of the words in a given year that are most associated with literature. Here's the list for 1900, pulling from pages that contain literature more than 3 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "from collections import OrderedDict\n",
    "from hol.models import Score\n",
    "\n",
    "topn = Score.topn_by_year(1790, 50)\n",
    "    \n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(topn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks sensible, with a couple curiosities (\"of\"?). With this in hand, the next step is to pull these stats for each year, and string together time-series signals for each word to get a diachronic progression of it's stickiness with literature. But, out-of-the-box, this doesn't work. The problem is that the log-likelihood scores can be used to compare words within an individual year, but not _across_ years, because the values are boosted by the overall volumes of the tokens. This is actually a feature of the log-likelihood, not a bug - when scoring a word, it rewards tokens that both (a) have a higher-than-expected frequency in the analysis corpus and (b) have a high overall frequency in the reference corpus. This is important, because otherwise the top of the list would be swamped by very infrequent words. For instance, something that was expected to appear 1 time but actually appeared 5 times. If you just compare the values directly, this comes out to a 500% increase over the expected. But, since the numbers are so small, this could just be a fluke - a single page out of millions. The intuition behind log-likelihood is that we care much more about a word that's expected to appear 1,000 times but actually occurs 1,200. Just a 20% increase, but we can say with much more confidence that the difference is meaningful.\n",
    "\n",
    "So, log-likelihood is great for ranking words inside of a single year, but if we string the raw scores together into a time series, we end up just proxying the overall volume trend. For example, here's the log-likelihood series for \"history\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = range(1750, 1920)\n",
    "\n",
    "series = Score.score_series_smooth('history', years)\n",
    "\n",
    "plt.title('Raw log-likelihood series')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Score')\n",
    "plt.plot(*zip(*series.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the baseline frequency trend for \"history\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = range(1750, 1920)\n",
    "\n",
    "series = Count.token_count_series_smooth('history', years)\n",
    "\n",
    "plt.title('Baseline volume trend')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(*zip(*series.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same data, essentially, just with different units. We need a way to normalize the magnitudes of the log-likelihoods, similar to the words-per-million scaling that we use on the overall frequencies. This turns out to be a tricky and interesting problem. At first, I tried just scaling everything down to \"unit variance\" - slide and compress the scores so that they center around 0 and have a variance of 1. But, when I plotted the transformed scores, the trend lines were basically unchanged - still just a proxy for volume.\n",
    "\n",
    "This doesn't work, I think, because _the total number of unique word forms in a year increases along with the overall volume_. In other words, if we see 1,000 total tokens in the year 1800 and 100 unique words, then in 1900 there might be 10,000 total tokens but _1,000_ unique words, not just more occurrences of the same set of 100. Most of these new words will be un-correlated with \"literature,\" which has the effect of packing in lots of low-correlation words right around the mean at 0. Which, in turn, allows the high-magnitude outliers (the ones we care about) to creep further and further away from 0 over time - shadowing the overall volume - even though the variance is pegged at 1.\n",
    "\n",
    "Next, I tried this - for each year, use the log-likelihoods to compute a rank order for each word. So, if there are N unique word forms for the year, the most correlated word has a rank of N, and the least correlated has a rank of 1. Since N grows over time, I then scaled these ranks down to a 0-1 scale and plotted time series for the normalized ranks. But, this fails for the same reason - over time, as the size of the corpus increases and more and more word types come into view, words get packed into the bottom of these rankings, which has the effect of artificially pushing up the ranks of the high-correlation words. Not because of any meaningful change in their correlation with literature, but just to make room for all the new, uncorrelated words that have to get crammed into the bottom of the stack.\n",
    "\n",
    "## Vocabulary cropping\n",
    "\n",
    "In both cases, the root of the problem is this enormous growth in the size of the vocabulary - as new words pour into the system, the correlation scores get artificially shoved upwards, which drowns out the meaingful fluctuations that we care about. How to fix this? Could we somehow crop down the vocabulary, identify a fixed subset of words that are meaningful across time?\n",
    "\n",
    "Here's what I came up with:\n",
    "\n",
    "1. For each year, compute log-likelihoods for all words and generate a 500-word \"depth chart,\" like the one above. This represents the 500 words that are most significantly correlated with literature in that year.\n",
    "\n",
    "1. Loop through all of these lists and build up a set of unique word forms that appear in _any_ of the lists. This gives a set of ~5,000 words that are highly correlated with \"literature\" in any year between 1750 and 1920.\n",
    "\n",
    "1. For each word in this cropped-down set, generate a time-series out of the word's position in the per-year ranks. Eg, for year X, if word Y is at the bottom of the list, it gets a score of 1, or if it's at the top, 500.\n",
    "\n",
    "So, to circle back to \"history\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from hol.topn_series import TopnSeries\n",
    "\n",
    "years = range(1750, 1920)\n",
    "\n",
    "topns = TopnSeries(years)\n",
    "\n",
    "series = topns.rank_series_smooth('history')\n",
    "\n",
    "plt.title('Rank time series')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Rank')\n",
    "plt.xlim(1750, 1920)\n",
    "plt.plot(*zip(*series.items()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History rockets to the top of the stack between 1890 and 19000, and stays almost (when not exactly) at the top through 1920 - a far cry from the raw log-likelihood signal, which tells a very misleading story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = range(1750, 1920)\n",
    "\n",
    "series = Score.score_series_smooth('history', years)\n",
    "\n",
    "plt.title('Raw log-likelihood series')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Score')\n",
    "plt.xlim(1750, 1920)\n",
    "plt.plot(*zip(*series.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting words\n",
    "\n",
    "Now, the final step - given the set of ~5k words that correlate with \"literature\" at some point between 1750 and 1920, how do we pick out words with _interesting_ signals - words that have a dynamic relationship with literature, that rise and fall over time, spike at some particular moment in history? This is essentially a signal processing problem, and there are a number of more and less sophisticated ways we could go about it.\n",
    "\n",
    "To start, though, I took a (very) simple approach - just compute the raw variance of the values in the time series. This actually seems to do a fairly good job - take a look at the appendix for a complete listing of the top 500 words, ranked in terms of signal variance. I think there's some very interesting stuff here. I won't go into it in too much detail at this point, other than to call out a handful of things that caught my eye.\n",
    "\n",
    "### Words about pedagogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_ranks(tokens):    \n",
    "    for token in tokens:\n",
    "\n",
    "        years = range(1750, 1920)\n",
    "        series = topns.rank_series_smooth(token)\n",
    "        \n",
    "        print(token)\n",
    "\n",
    "        plt.title(token)\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Log-likelihood rank')\n",
    "        plt.ylim(0, 1000)\n",
    "        plt.plot(*zip(*series.items()))\n",
    "        plt.show()\n",
    "    \n",
    "plot_ranks([\n",
    "    'lessons',\n",
    "    'instructor',\n",
    "    'educational',\n",
    "    'course',\n",
    "    'teaching',\n",
    "    'courses',\n",
    "    'schools',\n",
    "    'college',\n",
    "    'student',\n",
    "    'professor',\n",
    "    'pupils',\n",
    "    'academy',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'contract',\n",
    "    'pay',\n",
    "    'cent',\n",
    "    'paid',\n",
    "    'estate',\n",
    "    'bank',\n",
    "    'company',\n",
    "    'property',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'god',\n",
    "    'jesus',\n",
    "    'christ',\n",
    "    'lord',\n",
    "    'sin',\n",
    "    'biblical',\n",
    "    'religious',\n",
    "    'religion',\n",
    "    'christian',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scholarship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'scholarship',\n",
    "    'texts',\n",
    "    'comparative',\n",
    "    'criticism',\n",
    "    'studies',\n",
    "    'intellectual',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'renaissance',\n",
    "    'victorian',\n",
    "    'eighteenth',\n",
    "    'nineteenth',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres and formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'novel',\n",
    "    'romance',\n",
    "    'plays',\n",
    "    'essay',\n",
    "    'weekly',\n",
    "    'serial',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-improvement, pleasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'cultivation',\n",
    "    'taste',\n",
    "    'appreciation',\n",
    "    'useful',\n",
    "    'entertaining',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'homer',\n",
    "    'shakespeare',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sciences, hard and soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'sciences',\n",
    "    'scientific',\n",
    "    'physics',\n",
    "    'chemistry',\n",
    "    'psychology',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleverness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'genius',\n",
    "    'talent',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appraisal, judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'best',\n",
    "    'great',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'he',\n",
    "    'him',\n",
    "    'she',\n",
    "    'her'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'me',\n",
    "    'my',\n",
    "    'i',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nationalities, ethnicities, regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'jewish',\n",
    "    'irish', \n",
    "    'welsh',\n",
    "    'russian',\n",
    "    'greeks',\n",
    "    'polish',\n",
    "    'celtic',\n",
    "    'spanish',\n",
    "    'france',\n",
    "    'america',\n",
    "    'american',\n",
    "    'europe',\n",
    "    'european',\n",
    "    'italy',\n",
    "    'london',\n",
    "    'england',\n",
    "    'greece',\n",
    "    'boston',\n",
    "    'germany',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ranks([\n",
    "    'story',\n",
    "    'newspaper',\n",
    "    'printing',\n",
    "    'ideals',\n",
    "    'liberal',\n",
    "    'politics',\n",
    "    'translation',\n",
    "    'cloth',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
