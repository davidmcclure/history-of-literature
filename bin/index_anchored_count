#!/usr/bin/env python


import click

from collections import defaultdict, Counter

from hol.job import Job
from hol.models import AnchoredCount
from hol.volume import Volume



class IndexAnchoredCountJob(Job):


    def __init__(self, anchor, page_size=1000, *args, **kwargs):

        """
        Set the anchor token.

        Args:
            anchor (str)
            page_size (int)
        """

        super().__init__(*args, **kwargs)

        self.anchor = anchor

        self.page_size = page_size


    def process_paths(self, paths):

        """
        Accumulate counts for a set of paths.

        Args:
            paths (list)

        Returns: defaultdict(Counter)
        """

        result = defaultdict(lambda: defaultdict(Counter))

        for path in paths:

            try:

                vol = Volume.from_path(path)

                if vol.is_english:

                    counts = vol.anchored_token_counts(
                        self.anchor,
                        self.page_size,
                    )

                    for level, counts in counts.items():
                        result[vol.year][level] += counts

            except Exception as e:
                print(e)

        return dict(result)


    def flush_result(self, data):

        """
        Increment database counters.

        Args:
            data (dict)
        """

        AnchoredCount.flush(data)



@click.command()

@click.argument('anchor')

@click.option(
    '--group_size',
    help='Process the corpus in groups of N paths.',
    default=1000,
)

@click.option(
    '--page_size',
    help='Group pages into units of N tokens.',
    default=1000,
)

def index_anchored_count(anchor, group_size, page_size):

    """
    Index year -> token -> count.
    """

    job = IndexAnchoredCountJob(anchor, page_size, group_size)

    job.run()



if __name__ == '__main__':
    index_anchored_count()
